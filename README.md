# ğŸ¥’ Data Pickle Pipe

A simple Python pipeline that demonstrates how to **serialize and deserialize** data using the built-in `pickle` module. This project highlights how pickling can be used to efficiently store intermediate data in machine learning or ETL workflows.

## ğŸ¯ Purpose

- Save intermediate or final Python objects (e.g., DataFrames, models)
- Load pickled data for future reuse or continuation
- Simple, reusable interface for pipeline stages involving pickling

## ğŸ“ Project Structure

```text
data-pickle-pipe/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pickle_io.py        # Contains functions for pickling/unpickling data
â”‚   â””â”€â”€ main.py             # Sample pipeline that uses pickling
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw_data.csv        # Sample raw input (optional)
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ processed.pkl       # Pickled object
â”‚   â””â”€â”€ restored.csv        # Unpickled and saved data
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ demo.ipynb          # Interactive walkthrough
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## âœ… Use Cases
Save ML models between training and inference

Cache transformed data to speed up workflows

Backup Python objects in pipelines or applications

## ğŸ“Œ TODO
Add JSON and joblib serialization support

CLI support for batch pickling

Integrate with pandas pipeline stages

## ğŸ‘¤ Author
Saran Jaya Thilak
